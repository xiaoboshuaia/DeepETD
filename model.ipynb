{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# 示例数据，假设这两个列表分别代表所有样本中的不同细胞定位、疾病和细胞表型\n",
    "cell_locations = ['Nucleus', 'Cytoplasm', 'Mitochondria', 'Nucleus', 'Cytoplasm', 'Mitochondria', ...]\n",
    "diseases = ['Disease_A', 'Disease_B', 'Disease_C', 'Disease_A', 'Disease_B', 'Disease_C', ...]\n",
    "phenotypes = ['Phenotype_A', 'Phenotype_B', 'Phenotype_C', 'Phenotype_A', 'Phenotype_B', 'Phenotype_C', ...]\n",
    "\n",
    "# 创建 LabelEncoder 实例并进行编码\n",
    "location_encoder = LabelEncoder()\n",
    "disease_encoder = LabelEncoder()\n",
    "phenotype_encoder = LabelEncoder()\n",
    "\n",
    "# 将类别标签转换为整数ID\n",
    "location_ids = location_encoder.fit_transform(cell_locations)\n",
    "disease_ids = disease_encoder.fit_transform(diseases)\n",
    "phenotype_ids = phenotype_encoder.fit_transform(phenotypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设我们有多个样本，每个样本有10个细胞定位、10个疾病、10个细胞表型\n",
    "# 下面是每个样本的示例数据\n",
    "sample_1_locations = ['Nucleus', 'Cytoplasm', 'Mitochondria', 'Nucleus', 'Cytoplasm', 'Mitochondria', ...]\n",
    "sample_1_diseases = ['Disease_A', 'Disease_B', 'Disease_C', 'Disease_A', 'Disease_B', 'Disease_C', ...]\n",
    "sample_1_phenotypes = ['Phenotype_A', 'Phenotype_B', 'Phenotype_C', 'Phenotype_A', 'Phenotype_B', 'Phenotype_C', ...]\n",
    "\n",
    "# 为每个样本进行编码\n",
    "sample_1_location_ids = location_encoder.transform(sample_1_locations)\n",
    "sample_1_disease_ids = disease_encoder.transform(sample_1_diseases)\n",
    "sample_1_phenotype_ids = phenotype_encoder.transform(sample_1_phenotypes)\n",
    "\n",
    "# 构建最终的特征向量\n",
    "sample_1_feature_vector = np.concatenate([sample_1_location_ids, sample_1_disease_ids, sample_1_phenotype_ids])\n",
    "\n",
    "print(\"Sample 1 feature vector:\", sample_1_feature_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设有多个样本\n",
    "samples = [\n",
    "    {\n",
    "        'locations': ['Nucleus', 'Cytoplasm', 'Mitochondria', ...],\n",
    "        'diseases': ['Disease_A', 'Disease_B', 'Disease_C', ...],\n",
    "        'phenotypes': ['Phenotype_A', 'Phenotype_B', 'Phenotype_C', ...]\n",
    "    },\n",
    "    # 更多样本...\n",
    "]\n",
    "\n",
    "# 构建所有样本的特征向量\n",
    "all_feature_vectors = []\n",
    "\n",
    "for sample in samples:\n",
    "    location_ids = location_encoder.transform(sample['locations'])\n",
    "    disease_ids = disease_encoder.transform(sample['diseases'])\n",
    "    phenotype_ids = phenotype_encoder.transform(sample['phenotypes'])\n",
    "    \n",
    "    # 构建样本的特征向量\n",
    "    feature_vector = np.concatenate([location_ids, disease_ids, phenotype_ids])\n",
    "    all_feature_vectors.append(feature_vector)\n",
    "\n",
    "print(\"All feature vectors:\", all_feature_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设我们有对应的标签数据\n",
    "labels = np.array([1, 0, 1, ...])\n",
    "\n",
    "# 转换为PyTorch Tensor\n",
    "import torch\n",
    "\n",
    "features_tensor = torch.tensor(all_feature_vectors, dtype=torch.float32)\n",
    "labels_tensor = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "# 将数据和标签包装为数据集\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "dataset = TensorDataset(features_tensor, labels_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AttentionMechanism(nn.Module):\n",
    "    def __init__(self, feature_dim, hidden_dim):\n",
    "        super(AttentionMechanism, self).__init__()\n",
    "        self.fc1 = nn.Linear(feature_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, features):\n",
    "        attn_weights = F.relu(self.fc1(features))\n",
    "        attn_weights = torch.sigmoid(self.fc2(attn_weights))\n",
    "        return attn_weights\n",
    "\n",
    "class InteractionPredictionModel(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim):\n",
    "        super(InteractionPredictionModel, self).__init__()\n",
    "        self.embedding1 = nn.Linear(input_dim, embedding_dim)\n",
    "        self.embedding2 = nn.Linear(input_dim, embedding_dim)\n",
    "        self.attention = AttentionMechanism(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, metabolite_features, protein_features):\n",
    "        # Embed the features\n",
    "        metabolite_embedding = F.relu(self.embedding1(metabolite_features))\n",
    "        protein_embedding = F.relu(self.embedding2(protein_features))\n",
    "        \n",
    "        # Apply attention mechanism\n",
    "        attn_weights = self.attention(protein_embedding)\n",
    "        weighted_protein_embedding = attn_weights * protein_embedding\n",
    "        \n",
    "        # Concatenate metabolite and weighted protein features\n",
    "        combined_features = torch.cat((metabolite_embedding, weighted_protein_embedding), dim=1)\n",
    "        \n",
    "        # Predict interaction score\n",
    "        interaction_score = torch.sigmoid(self.fc(combined_features))\n",
    "        return interaction_score\n",
    "\n",
    "# Example usage\n",
    "input_dim = 100  # Example input dimension for metabolite/protein features\n",
    "embedding_dim = 64  # Embedding dimension for both metabolite and protein features\n",
    "hidden_dim = 128  # Hidden dimension for the attention mechanism and fully connected layers\n",
    "\n",
    "model = InteractionPredictionModel(input_dim, embedding_dim, hidden_dim)\n",
    "\n",
    "# Dummy inputs\n",
    "metabolite_features = torch.randn((1, input_dim))  # Batch size of 1\n",
    "protein_features = torch.randn((1, input_dim))\n",
    "\n",
    "# Forward pass\n",
    "interaction_score = model(metabolite_features, protein_features)\n",
    "print(interaction_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class InteractionDataset(Dataset):\n",
    "    def __init__(self, metabolite_features, protein_features, labels):\n",
    "        self.metabolite_features = metabolite_features\n",
    "        self.protein_features = protein_features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.metabolite_features[idx], self.protein_features[idx], self.labels[idx]\n",
    "\n",
    "# 生成数据集实例\n",
    "train_dataset = InteractionDataset(train_metabolite_features, train_protein_features, train_labels)\n",
    "val_dataset = InteractionDataset(val_metabolite_features, val_protein_features, val_labels)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCELoss()  # 二分类交叉熵损失\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam优化器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20  # 设置训练的epoch数\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for metabolite_features, protein_features, labels in train_loader:\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(metabolite_features, protein_features).squeeze()\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "    \n",
    "    # 验证阶段\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for metabolite_features, protein_features, labels in val_loader:\n",
    "            outputs = model(metabolite_features, protein_features).squeeze()\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # 计算准确率\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    print(f'Validation Loss: {val_loss/len(val_loader):.4f}, Accuracy: {100 * correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# 假设我们有以下数据结构\n",
    "# proteins_data = [(\"protein1\", diseases, localization, phenotypes), ...]\n",
    "# compounds_data = [(\"compound1\", diseases, localization, phenotypes), ...]\n",
    "\n",
    "# 定义类别数量\n",
    "num_disease_categories = 1000\n",
    "num_phenotype_categories = 1000\n",
    "num_localization_categories = 30\n",
    "\n",
    "# 每种类别我们会用一个Embedding层进行处理\n",
    "disease_embedding_dim = 64\n",
    "phenotype_embedding_dim = 64\n",
    "localization_embedding_dim = 16\n",
    "\n",
    "class FeatureEmbedding(nn.Module):\n",
    "    def __init__(self, num_categories, embedding_dim):\n",
    "        super(FeatureEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_categories, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)\n",
    "\n",
    "# 定义蛋白质和化合物的嵌入层\n",
    "disease_embedding = FeatureEmbedding(num_disease_categories, disease_embedding_dim)\n",
    "phenotype_embedding = FeatureEmbedding(num_phenotype_categories, phenotype_embedding_dim)\n",
    "localization_embedding = FeatureEmbedding(num_localization_categories, localization_embedding_dim)\n",
    "\n",
    "def encode_features(data, disease_embedding, phenotype_embedding, localization_embedding):\n",
    "    diseases, localization, phenotypes = [], [], []\n",
    "    for _, d, l, p in data:\n",
    "        diseases.append(d)\n",
    "        localization.append(l)\n",
    "        phenotypes.append(p)\n",
    "    \n",
    "    diseases = torch.tensor(diseases, dtype=torch.long)\n",
    "    localization = torch.tensor(localization, dtype=torch.long)\n",
    "    phenotypes = torch.tensor(phenotypes, dtype=torch.long)\n",
    "    \n",
    "    disease_features = disease_embedding(diseases).sum(dim=1)\n",
    "    localization_features = localization_embedding(localization).sum(dim=1)\n",
    "    phenotype_features = phenotype_embedding(phenotypes).sum(dim=1)\n",
    "    \n",
    "    return torch.cat([disease_features, localization_features, phenotype_features], dim=1)\n",
    "\n",
    "# 对蛋白质和化合物的特征进行编码\n",
    "protein_features = encode_features(proteins_data, disease_embedding, phenotype_embedding, localization_embedding)\n",
    "compound_features = encode_features(compounds_data, disease_embedding, phenotype_embedding, localization_embedding)\n",
    "\n",
    "# 将蛋白质和化合物特征拼接在一起\n",
    "features = torch.cat([protein_features, compound_features], dim=1)\n",
    "\n",
    "# 假设labels为0或1的标签\n",
    "labels = torch.tensor([0, 1, 0, 1, ...], dtype=torch.float32).unsqueeze(1)  # 与数据对齐的标签\n",
    "\n",
    "# 分割数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义模型（代码同前）\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_weights = self.attention(x)\n",
    "        attn_weights = torch.softmax(attn_weights, dim=1)\n",
    "        weighted_input = x * attn_weights\n",
    "        return weighted_input.sum(dim=1)\n",
    "\n",
    "class InteractionModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(InteractionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.attention = AttentionLayer(hidden_dim, hidden_dim // 2)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.fc3 = nn.Linear(hidden_dim // 2, 1)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.attention(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "# 计算AUC-ROC分数\n",
    "def calculate_auc_roc(model, X, y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = torch.tensor(X, dtype=torch.float32)\n",
    "        labels = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "        outputs = model(inputs)\n",
    "        auc_roc = roc_auc_score(labels.numpy(), outputs.numpy())\n",
    "        return auc_roc, outputs.numpy()\n",
    "\n",
    "# 训练模型，并在每个epoch后计算训练集和验证集的Loss和AUC-ROC\n",
    "def train_model(model, X_train, y_train, X_test, y_test, criterion, optimizer, scheduler, epochs=20, patience=5):\n",
    "    best_auc_roc = 0.0\n",
    "    best_epoch = 0\n",
    "    best_model_wts = model.state_dict()\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        inputs = torch.tensor(X_train, dtype=torch.float32)\n",
    "        labels = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        train_loss = criterion(outputs, labels)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 计算训练集的AUC-ROC\n",
    "        train_auc_roc, _ = calculate_auc_roc(model, X_train, y_train)\n",
    "\n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_inputs = torch.tensor(X_test, dtype=torch.float32)\n",
    "            val_labels = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "            val_outputs = model(val_inputs)\n",
    "            val_loss = criterion(val_outputs, val_labels)\n",
    "            val_auc_roc, val_predictions = calculate_auc_roc(model, X_test, y_test)\n",
    "\n",
    "        # 更新学习率调度器\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # 检查是否有最佳AUC-ROC（基于验证集）\n",
    "        if val_auc_roc > best_auc_roc:\n",
    "            best_auc_roc = val_auc_roc\n",
    "            best_epoch = epoch\n",
    "            best_model_wts = model.state_dict()\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        # 输出当前epoch的训练集和验证集表现\n",
    "        print(f'Epoch [{epoch+1}/{epochs}]')\n",
    "        print(f'Train Loss: {train_loss.item():.4f}, Train AUC-ROC: {train_auc_roc:.4f}')\n",
    "        print(f'Val Loss: {val_loss.item():.4f}, Val AUC-ROC: {val_auc_roc:.4f}')\n",
    "\n",
    "        # 每5个epoch绘制一次验证集的ROC曲线\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            plot_roc_curve(val_labels.numpy(), val_predictions)\n",
    "\n",
    "        # 实现早停\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f'Early stopping triggered. Best Val AUC-ROC: {best_auc_roc:.4f} at epoch {best_epoch+1}.')\n",
    "            break\n",
    "\n",
    "    # 恢复最佳模型权重\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "# 数据准备（前述数据处理步骤）\n",
    "# X_train, X_test, y_train, y_test = ...\n",
    "\n",
    "# 初始化模型\n",
    "input_dim = X_train.shape[1]  # 输入维度是特征数\n",
    "hidden_dim = 256  # 隐藏层维度，可以调整\n",
    "\n",
    "model = InteractionModel(input_dim, hidden_dim)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "# 开始训练\n",
    "train_model(model, X_train, y_train, X_test, y_test, criterion, optimizer, scheduler, epochs=20, patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设新的数据集与之前的数据集结构相同\n",
    "# new_proteins_data = ...\n",
    "# new_compounds_data = ...\n",
    "\n",
    "# 使用相同的嵌入层对新数据集进行编码\n",
    "new_protein_features = encode_features(new_proteins_data, disease_embedding, phenotype_embedding, localization_embedding)\n",
    "new_compound_features = encode_features(new_compounds_data, disease_embedding, phenotype_embedding, localization_embedding)\n",
    "\n",
    "# 拼接蛋白质和化合物的特征\n",
    "new_features = torch.cat([new_protein_features, new_compound_features], dim=1)\n",
    "\n",
    "# 假设你已经保存了训练好的模型\n",
    "# torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# 加载模型\n",
    "model = InteractionModel(input_dim, hidden_dim)\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# 确保模型处于评估模式\n",
    "model.eval()\n",
    "\n",
    "# 进行预测\n",
    "with torch.no_grad():\n",
    "    new_inputs = new_features.float()  # 将数据转换为浮点类型张量\n",
    "    predictions = model(new_inputs)\n",
    "\n",
    "# 将预测结果转化为二进制标签或概率\n",
    "binary_predictions = (predictions > 0.5).int()  # 0 或 1\n",
    "probability_predictions = predictions.numpy()  # 概率值\n",
    "\n",
    "# 保存预测结果\n",
    "np.savetxt(\"predictions.csv\", binary_predictions.numpy(), delimiter=\",\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
